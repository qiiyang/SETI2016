{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "import math\n",
    "import string\n",
    "import datetime\n",
    "import numpy as np\n",
    "import matplotlib.pyplot\n",
    "from pyspark.sql.types import *\n",
    "from pyspark.sql import SQLContext\n",
    "from pyspark.sql import Row\n",
    "import pylab\n",
    "sqlContext = SQLContext(sc)\n",
    "\n",
    "%matplotlib inline"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def config_softlayer_acct(name, auth_url, username, password):\n",
    "   prefix = \"fs.swift.service.\" + name\n",
    "   hconf = sc._jsc.hadoopConfiguration()\n",
    "   hconf.set(prefix + \".auth.url\", auth_url)\n",
    "   hconf.set(prefix + \".username\", username)\n",
    "   hconf.set(prefix + \".tenant\", username)\n",
    "   hconf.set(prefix + \".auth.endpoint.prefix\", \"endpoints\")\n",
    "   hconf.setInt(prefix + \".http.port\", 8080)\n",
    "   hconf.set(prefix + \".apikey\", password)\n",
    "   hconf.setBoolean(prefix + \".public\", True)\n",
    "   hconf.set(prefix + \".use.get.auth\", \"true\")\n",
    "   hconf.setBoolean(prefix + \".location-aware\", False)\n",
    "   hconf.set(prefix + \".password\", password)\n",
    "\n",
    "config_softlayer_acct(\"seti\",\"https://dal05.objectstorage.softlayer.net/auth/v1.0\",\"IBMOS294544-2:npoore@us.ibm.com\",\"abde9540378cd1e662de10df155ea50ccd88a6137af5575cc639957e6b635b7d\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "def parseLineIgnoreHeaders(line):\n",
    "    words = []\n",
    "    if line.startswith('UniqueId'):\n",
    "        return words\n",
    "    words = line\n",
    "    return words\n",
    "\n",
    "sqlContext = SQLContext(sc)\n",
    "\n",
    "data = sc.textFile(\"swift://setiSignalDB.seti/*\")\n",
    "\n",
    "dataForRowNames = sc.textFile(\"swift://setiSignalDB.seti/xaa\")\n",
    "rowNames = dataForRowNames.first().split(\"\\t\")\n",
    "\n",
    "rowNamesClear = []\n",
    "\n",
    "#We need to modify column names with \"/\" in it, because of issues when call these columns later\n",
    "for name in rowNames:\n",
    "    if name.find(\"/\"):\n",
    "        rowNamesClear.append(name.replace(\"/\",\"\"))\n",
    "    else: \n",
    "        rowNamesClear.append(name)\n",
    "\n",
    "cleanData = data.map(lambda line:parseLineIgnoreHeaders(line)).filter(lambda words: len(words)>0)\n",
    "rowRDD = cleanData.map(lambda line:line.split(\"\\t\")).map(lambda d:(d[0],d[1],d[2],d[3],d[4],d[5],d[6],d[7],d[8],d[9], d[10],d[11],d[12],d[13],d[14],d[15],d[16],d[17],d[18],d[19],d[20],d[21],d[22]))\n",
    "\n",
    "fields = [StructField(field_name, StringType(), True) for field_name in rowNamesClear]\n",
    "schema = StructType(fields)\n",
    "\n",
    "# Create a Dataframe of the entire Signal database ~ 200M rows\n",
    "fullSetiDataFrame = sqlContext.createDataFrame(rowRDD, schema)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "196816238"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "fullSetiDataFrame.count()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+--------------------+-------------------+----------+------+-------+--------+----------+-------+----+--------------+--------+-----+----+------+--------+----+--------+---------+---------+------+--------+---------+----------+\n",
      "|            UniqueId|               Time|    ActTyp| TgtId|catalog|RA2000Hr|Dec2000Deg|  Power| SNR|       FreqMHz|DriftHzs|WidHz| Pol|SigTyp|PPeriodS|NPul|IntTimeS|TscpAzDeg|TscpElDeg|BeamNo|SigClass|SigReason|CandReason|\n",
      "+--------------------+-------------------+----------+------+-------+--------+----------+-------+----+--------------+--------+-----+----+------+--------+----+--------+---------+---------+------+--------+---------+----------+\n",
      "| antisolar_14_36_0_1|2010-06-11 21:02:54|target1off|109471| habcat|  13.236|   -14.282|166.000|NULL|1424.974541161|  -0.315|0.662|both|   CwP|    NULL|NULL|      98|  180.330|   34.862|     3|    Cand|   PsPwrT|   SnMulBm|\n",
      "| antisolar_14_29_0_2|2010-06-11 21:02:55|target1off|109539| habcat|  13.302|   -14.780|182.000|NULL|1424.974536525|  -0.260|1.987|both|   CwP|    NULL|NULL|      98|  180.330|   34.862|     2|    Cand|   PsPwrT|   SnMulBm|\n",
      "| antisolar_14_32_0_3|2010-06-11 21:02:55|target1off|109471| habcat|  13.236|   -14.282|252.000|NULL| 1420.03104451|   0.027|3.974|both|   CwP|    NULL|NULL|      98|  180.330|   34.862|     3|    Cand|   PsPwrT|   SnMulBm|\n",
      "| antisolar_14_32_1_4|2010-06-11 21:02:55|target1off|109471| habcat|  13.236|   -14.282|164.000|NULL|1420.031664398|  -0.021|0.662|both|   CwP|    NULL|NULL|      98|  180.330|   34.862|     3|    Cand|   PsPwrT|   SnMulBm|\n",
      "| antisolar_14_33_0_5|2010-06-11 21:02:55|target1off|109471| habcat|  13.236|   -14.282|246.000|NULL| 1420.03104451|   0.027|3.974|both|   CwP|    NULL|NULL|      98|  180.330|   34.862|     3|    Cand|   PsPwrT|   SnMulBm|\n",
      "| antisolar_14_32_2_6|2010-06-11 21:02:55|target1off|109471| habcat|  13.236|   -14.282|194.000|NULL|1420.036487738|   0.103|1.325|both|   CwP|    NULL|NULL|      98|  180.330|   34.862|     3|    Cand|   PsPwrT|   SnMulBm|\n",
      "| antisolar_14_33_1_7|2010-06-11 21:02:55|target1off|109471| habcat|  13.236|   -14.282|216.000|NULL|1420.035175774|  -0.027|1.325|both|   CwP|    NULL|NULL|      98|  180.330|   34.862|     3|    Cand|   PsPwrT|   SnMulBm|\n",
      "| antisolar_14_31_0_8|2010-06-11 21:02:55|target1off|109539| habcat|  13.302|   -14.780|176.000|NULL|1428.390181356|   0.130|3.311|both|   CwP|    NULL|NULL|      98|  180.330|   34.862|     2|    Cand|   PsPwrT|   SnMulBm|\n",
      "| antisolar_14_32_3_9|2010-06-11 21:02:55|target1off|109471| habcat|  13.236|   -14.282|188.000|NULL| 1420.03810766|   0.000|1.325|both|   CwP|    NULL|NULL|      98|  180.330|   34.862|     3|     RFI|  ZeroDft|      NULL|\n",
      "|antisolar_14_33_2_10|2010-06-11 21:02:55|target1off|109471| habcat|  13.236|   -14.282|194.000|NULL|1420.036487738|   0.103|1.987|both|   CwP|    NULL|NULL|      98|  180.330|   34.862|     3|    Cand|   PsPwrT|   SnMulBm|\n",
      "+--------------------+-------------------+----------+------+-------+--------+----------+-------+----+--------------+--------+-----+----+------+--------+----+--------+---------+---------+------+--------+---------+----------+\n",
      "\n"
     ]
    }
   ],
   "source": [
    "fullSetiDataFrame.show(10)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### The next cell commented out, but shows how to read/write parquet files to avoid the text dump parse/load in the cell above"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "# uncomment the folloing line if you want to save the  data as a parquet file. \n",
    "# Parquets are columnar store formats, and makes it easy/faster to re-load the data for later use... see commented text below.\n",
    "#fullSetiDataFrame.write.parquet(\"signalDB.parquet\")\n",
    "\n",
    "# uncomment this line if the signalDB parquet already exists. You can load it directly into the dataframe and skip the text dump parse and load in the cell above\n",
    "#fullSetiDataFrame = sqlContext.read.parquet(\"signalDB.parquet\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "collapsed": false
   },
   "source": [
    "### Example query of signalDB dataframe... this creates a new dataframe containing only those signal event records which are confimed 'candidate' signals with a stored archive-CompAmp file"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "288802"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# create a DF of just the confirmed signals\n",
    "# Replace this SQL statement with any queries or sequences of queries to mine the signal database for matching records and patterns\n",
    "\n",
    "fullSetiDataFrame.registerTempTable(\"signaldb\")\n",
    "confirmedSignalsDF = sqlContext.sql(\"SELECT * FROM signaldb WHERE SigClass='Cand' AND CandReason IN ('PsPwrT', 'RConfrm', 'PsCohD', 'Confrm')\")\n",
    "confirmedSignalsDF.count()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# uncomment the folloing line if you want to save the confirmed signal data as a parquet file. \n",
    "# This will allow you to directly load the parquet into a dataframe in the future and begin processing the confirmed candidate \n",
    "# signals without repeating any of the preceeding steps.\n",
    "\n",
    "#confirmedSignalsDF.write.parquet(\"confirmedSignalDB.parquet\")"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 2",
   "language": "python",
   "name": "python2"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.9"
  },
  "name": "SETI parquet management"
 },
 "nbformat": 4,
 "nbformat_minor": 0
}